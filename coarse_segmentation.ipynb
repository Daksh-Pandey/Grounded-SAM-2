{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pynvml\n",
    "\n",
    "def get_least_used_gpu():\n",
    "    \"\"\"\n",
    "    Finds the GPU with the lowest memory utilization and sets it as the device.\n",
    "\n",
    "    Returns:\n",
    "        str: Device to use (\"cuda:x\" for GPU or \"cpu\" if no GPU is available).\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"No GPU available. Using CPU.\")\n",
    "        return \"cpu\"\n",
    "\n",
    "    # Initialize NVIDIA Management Library\n",
    "    pynvml.nvmlInit()\n",
    "    device_count = pynvml.nvmlDeviceGetCount()\n",
    "\n",
    "    min_usage = float(\"inf\")\n",
    "    best_gpu = None\n",
    "\n",
    "    for i in range(device_count):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "        # Calculate memory usage percentage\n",
    "        used_memory = info.used / info.total * 100  # Memory usage in percentage\n",
    "        # print(f\"GPU {i}: {used_memory:.2f}% memory used.\")\n",
    "\n",
    "        # Track the GPU with the lowest memory usage\n",
    "        if used_memory < min_usage:\n",
    "            min_usage = used_memory\n",
    "            best_gpu = i\n",
    "\n",
    "    # Cleanup NVML\n",
    "    pynvml.nvmlShutdown()\n",
    "\n",
    "    if best_gpu is not None:\n",
    "        print(f\"Using GPU {best_gpu} (lowest memory usage: {min_usage:.2f}%).\")\n",
    "        return f\"cuda:{best_gpu}\"\n",
    "    else:\n",
    "        print(\"No suitable GPU found. Using CPU.\")\n",
    "        return \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0 (lowest memory usage: 2.49%).\n"
     ]
    }
   ],
   "source": [
    "from pytorch3d.io import load_objs_as_meshes\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "DEVICE = get_least_used_gpu()\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = \"./data\"\n",
    "obj_filename = os.path.join(DATA_DIR, \"dog_mesh/13466_Canaan_Dog_v1_L3.obj\")\n",
    "\n",
    "# Load obj file\n",
    "mesh = load_objs_as_meshes([obj_filename], device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ip_arul/daksh21036/miniconda3/envs/grounded_sam2/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/ip_arul/daksh21036/miniconda3/envs/grounded_sam2/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789115765/work/aten/src/ATen/native/TensorShape.cpp:3609.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.ops import box_convert\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from grounding_dino.groundingdino.util.inference import load_model, load_image, predict\n",
    "\n",
    "\n",
    "SAM2_CHECKPOINT = \"./checkpoints/sam2.1_hiera_large.pt\"\n",
    "SAM2_MODEL_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "GROUNDING_DINO_CONFIG = \"grounding_dino/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT = \"gdino_checkpoints/groundingdino_swint_ogc.pth\"\n",
    "BOX_THRESHOLD = 0.35\n",
    "DATA_DIR = \"./data\"\n",
    "TEXT_THRESHOLD = 0.25\n",
    "\n",
    "# build SAM2 image predictor\n",
    "sam2_checkpoint = SAM2_CHECKPOINT\n",
    "model_cfg = SAM2_MODEL_CONFIG\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=DEVICE)\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# build grounding dino model\n",
    "grounding_model = load_model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG, \n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "def grounded_sam2(img_path: str, text_prompt: str):\n",
    "    # setup the input image and text prompt for SAM 2 and Grounding DINO\n",
    "    # VERY important: text queries need to be lowercased + end with a dot\n",
    "    text = text_prompt\n",
    "\n",
    "    image_source, image = load_image(img_path)\n",
    "\n",
    "    sam2_predictor.set_image(image_source)\n",
    "\n",
    "    # FIXME: figure how does this influence the G-DINO model\n",
    "    # changed bfloat16 to float16\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "\n",
    "        if torch.cuda.get_device_properties(torch.device(DEVICE)).major >= 8:\n",
    "            # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "        boxes, confidences, labels = predict(\n",
    "            model=grounding_model,\n",
    "            image=image,\n",
    "            caption=text,\n",
    "            box_threshold=BOX_THRESHOLD,\n",
    "            text_threshold=TEXT_THRESHOLD,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "        # process the box prompt for SAM 2\n",
    "        h, w, _ = image_source.shape\n",
    "        boxes = boxes * torch.Tensor([w, h, w, h])\n",
    "        input_boxes = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
    "\n",
    "        if input_boxes.size == 0:\n",
    "            print(f\"No objects detected in {img_path}. Skipping this image.\")\n",
    "            return None\n",
    "\n",
    "        masks, scores, logits = sam2_predictor.predict(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            box=input_boxes,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Post-process the output of the model to get the masks, scores, and logits for visualization\n",
    "        \"\"\"\n",
    "        # convert the shape to (n, H, W)\n",
    "        if masks.ndim == 4:\n",
    "            masks = masks.squeeze(1)\n",
    "\n",
    "\n",
    "        confidences = confidences.numpy().tolist()\n",
    "        class_names = labels\n",
    "\n",
    "        class_ids = np.array(list(range(len(class_names))))\n",
    "\n",
    "        # labels = [\n",
    "        #     f\"{class_name} {confidence:.2f}\"\n",
    "        #     for class_name, confidence\n",
    "        #     in zip(class_names, confidences)\n",
    "        # ]\n",
    "\n",
    "        labels = [class_name for class_name in class_names]\n",
    "\n",
    "    return masks, labels   # return sam2 masks and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n"
     ]
    }
   ],
   "source": [
    "img_path = \"data/dog_mesh_views/view_00.png\"\n",
    "x = grounded_sam2(img_path, text_prompt=\"head. tail. legs.\")\n",
    "arr = x[0]\n",
    "print(np.unique(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    PerspectiveCameras,\n",
    "    RasterizationSettings,\n",
    "    MeshRasterizer,\n",
    "    MeshRenderer,\n",
    "    SoftPhongShader,\n",
    "    PointLights\n",
    ")\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "\n",
    "def calculate_matrix_Xi(\n",
    "    obj_file_path: str,\n",
    "    batch_size: int,\n",
    "    text_prompt: str,\n",
    "    elevs: tuple,\n",
    "    azims: tuple,\n",
    "    save_dir: str,\n",
    "    device: str = DEVICE\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the face-region matrix X_i for a given mesh using grounded_sam2 masks.\n",
    "\n",
    "    Args:\n",
    "        obj_file_path (str): Path to the OBJ file representing the 3D mesh.\n",
    "        batch_size (int): Number of images to render in a batch.\n",
    "        text_prompt (str): Input text for grounded_sam2.\n",
    "        elevs (tuple): Elevation range (start, end) in degrees.\n",
    "        azims (tuple): Azimuth range (start, end) in degrees.\n",
    "        device (str): Device to run the computation on (\"cuda:x\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Matrix X_i of shape (num_faces, num_regions).\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Load the mesh from the OBJ file\n",
    "    mesh = load_objs_as_meshes([obj_file_path], device=device)\n",
    "    num_faces = mesh.faces_packed().shape[0]\n",
    "\n",
    "    # Parse semantic regions from text_prompt (labels end with '.')\n",
    "    labels = text_prompt.strip().split('.')[:-1]\n",
    "    num_regions = len(labels)\n",
    "    labels_dict = {}\n",
    "    for idx in range(len(labels)):\n",
    "        labels_dict[labels[idx]] = idx\n",
    "\n",
    "    # Initialize the face-region matrix Xi with zeros\n",
    "    Xi = torch.zeros((num_faces, num_regions), device=device)\n",
    "\n",
    "    # Generate rasterization and rendering settings\n",
    "    raster_settings = RasterizationSettings(\n",
    "        image_size=512,  # Customize based on desired output resolution\n",
    "        blur_radius=0.0,\n",
    "        faces_per_pixel=1,  # Nearest face only\n",
    "        max_faces_per_bin=30000\n",
    "    )\n",
    "\n",
    "    # batched meshes\n",
    "    meshes = mesh.extend(batch_size)\n",
    "\n",
    "    # Create batches of elevation and azimuth angles\n",
    "    elev_angles = torch.linspace(elevs[0], elevs[1], batch_size)\n",
    "    azim_angles = torch.linspace(azims[0], azims[1], batch_size)\n",
    "    # elev_grid, azim_grid = torch.meshgrid(elev_angles, azim_angles, indexing=\"ij\")\n",
    "    # elev_grid, azim_grid = elev_grid.flatten(), azim_grid.flatten()\n",
    "    R, T = look_at_view_transform(60, elev=elev_angles, azim=azim_angles)\n",
    "\n",
    "    # Create batched cameras\n",
    "    cameras = PerspectiveCameras(\n",
    "        device=device,\n",
    "        R=R,\n",
    "        T=T\n",
    "    )\n",
    "\n",
    "    # lights\n",
    "    lights = PointLights(device=device, location=[[0.0, 0.0, -70.0]])\n",
    "\n",
    "    # Initialize the rasterizer and shade\n",
    "    rasterizer = MeshRasterizer(cameras=cameras, raster_settings=raster_settings)\n",
    "    shader = SoftPhongShader(device=device, cameras=cameras, lights=lights)\n",
    "\n",
    "\n",
    "    # Render the images if needed (optional, just to save them)\n",
    "    renderer = MeshRenderer(rasterizer=rasterizer, shader=shader)\n",
    "    images = renderer(meshes, cameras=cameras, lights=lights)\n",
    "    \n",
    "    # Rasterize the mesh to get the fragments\n",
    "    fragments = rasterizer(meshes_world=meshes)\n",
    "\n",
    "    # Now access pix_to_face from fragments\n",
    "    pix_to_face = fragments.pix_to_face[..., 0]  # Shape: (B, H, W)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for batch_idx in range(pix_to_face.shape[0]):\n",
    "        # Extract the RGB channels (H, W, 3)\n",
    "        rgb_image = images[batch_idx, ..., :3]  # Take only RGB channels\n",
    "\n",
    "        # Convert to uint8 (0-255 range) if needed\n",
    "        rgb_image = (rgb_image.clamp(0, 1) * 255).byte()\n",
    "\n",
    "        # Convert to PIL image and save\n",
    "        image_pil = ToPILImage()(rgb_image.permute(2, 0, 1).cpu())  # (C, H, W) for ToPILImage\n",
    "        image_path = f\"{save_dir}/view_{batch_idx:02d}.png\"\n",
    "        image_pil.save(image_path)\n",
    "        \n",
    "        # Use grounded_sam2 to get masks and labels for each rendered image\n",
    "        sam2_masks, sam2_labels = grounded_sam2(image_path, text_prompt)\n",
    "\n",
    "        # Iterate through all masks in sam2_masks\n",
    "        for mask_idx, label in enumerate(sam2_labels):\n",
    "            # Map the label to its corresponding region index using labels_dict\n",
    "            if label not in labels_dict:\n",
    "                continue  # Skip unknown labels\n",
    "\n",
    "            region_idx = labels_dict[label]  # Get the column index for this region\n",
    "\n",
    "            # Convert the corresponding 2D mask to a PyTorch tensor\n",
    "            region_mask = torch.tensor(sam2_masks[mask_idx] == 1, device=device)  # Foreground is 1\n",
    "\n",
    "            # Extract valid face indices using the region mask\n",
    "            valid_face_indices = pix_to_face[batch_idx][region_mask]\n",
    "            valid_face_indices = valid_face_indices[valid_face_indices >= 0]  # Ignore background (-1)\n",
    "            valid_face_indices %= num_faces\n",
    "\n",
    "            if valid_face_indices.numel() > 0:  # If there are valid faces\n",
    "                # Count occurrences of each face\n",
    "                face_counts = torch.bincount(valid_face_indices, minlength=num_faces)\n",
    "\n",
    "                # Update the face-region matrix Xi\n",
    "                Xi[:, region_idx] += face_counts\n",
    "\n",
    "    return Xi.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29.]\n"
     ]
    }
   ],
   "source": [
    "text_prompt = \"head. tail. legs. body.\"\n",
    "obj_file_path = \"data/dog_mesh/13466_Canaan_Dog_v1_L3.obj\"\n",
    "save_dir = \"./data/dog_mesh_views\"\n",
    "batch_size = 30\n",
    "\n",
    "Xi = calculate_matrix_Xi(obj_file_path=obj_file_path,\n",
    "                    batch_size=batch_size,\n",
    "                    text_prompt=text_prompt,\n",
    "                    elevs=(30, 40),\n",
    "                    azims=(-180, 180),\n",
    "                    save_dir=save_dir,\n",
    "                    device=DEVICE)\n",
    "print(np.unique(Xi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grounded_sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
